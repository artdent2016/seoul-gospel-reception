
import React, { useState, useEffect, useCallback, useRef } from 'react';
import { Mic, MicOff, CheckCircle, ChevronRight, User, Calendar, Phone, Stethoscope, Send, AlertCircle, Volume2, ArrowRight, Edit3 } from 'lucide-react';

const DISCORD_WEBHOOK_URL = import.meta.env?.VITE_DISCORD_WEBHOOK_URL || "";
const GEMINI_API_KEY = import.meta.env?.VITE_GEMINI_API_KEY || "";
const GEMINI_MODEL = "gemini-2.5-flash-preview-09-2025";

const STEPS = [
  { id: 'welcome', label: 'ì‹œì‘', question: 'ì•ˆë…•í•˜ì„¸ìš”. ì„œìš¸ë³µìŒì¹˜ê³¼ì…ë‹ˆë‹¤. ì ‘ìˆ˜ë¥¼ ì‹œì‘í•˜ë ¤ë©´ ì•„ë˜ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.' },
  { id: 'name', label: 'ì„±í•¨', question: 'ì„±í•¨ì„ ë§ì”€í•´ ì£¼ì‹œê±°ë‚˜ ì…ë ¥í•´ ì£¼ì„¸ìš”.', placeholder: 'ì´ë¦„ ì…ë ¥' },
  { id: 'birth', label: 'ìƒë…„ì›”ì¼', question: 'ìƒë…„ì›”ì¼ 8ìë¦¬ë¥¼ ë§ì”€í•´ ì£¼ì„¸ìš”.', placeholder: 'ì˜ˆ: 1990ë…„ 01ì›” 01ì¼' },
  { id: 'phone', label: 'ì—°ë½ì²˜', question: 'ì—°ë½ì²˜ë¥¼ ë§ì”€í•´ ì£¼ì„¸ìš”.', placeholder: 'ì˜ˆ: 01012345678' },
  { id: 'symptoms', label: 'ì¦ìƒ ì„¤ëª…', question: 'ì–´ë””ê°€ ì–´ë–»ê²Œ ë¶ˆí¸í•˜ì‹ ì§€ í¸í•˜ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”.', placeholder: 'ë¶ˆí¸í•˜ì‹  ê³³ì„ ìƒì„¸íˆ ë§ì”€í•´ ì£¼ì„¸ìš”' },
  { id: 'confirm', label: 'ë‚´ìš© í™•ì¸', question: 'ì…ë ¥í•˜ì‹  ë‚´ìš©ì´ ë§ëŠ”ì§€ í™•ì¸í•´ ì£¼ì„¸ìš”.' },
  { id: 'complete', label: 'ì™„ë£Œ', question: 'ì ‘ìˆ˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë³‘ì›ì—ì„œ í™•ì¸ í›„ ê³§ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤.' }
];

const App = () => {
  const [currentStepIndex, setCurrentStepIndex] = useState(0);
  const [formData, setFormData] = useState({ name: '', birth: '', phone: '', symptomsRaw: '', symptomsSummary: '' });
  const [isListening, setIsListening] = useState(false);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isProcessing, setIsProcessing] = useState(false);
  const [transcript, setTranscript] = useState('');
  const [error, setError] = useState('');
  const [isEditingMode, setIsEditingMode] = useState(false);

  const recognitionRef = useRef(null);
  const summaryTimeoutRef = useRef(null);
  const currentStep = STEPS[currentStepIndex];

  const summarizeSymptoms = async (rawText) => {
    if (!rawText || rawText.length < 3) return;
    setIsProcessing(true);
    const systemPrompt = "ë‹¹ì‹ ì€ ì¹˜ê³¼ë¥¼ ë°©ë¬¸í•œ í™˜ìì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ë§í•œ ì¦ìƒì„ ì›ì¥ë‹˜ê»˜ ì§ì ‘ ë§í•˜ëŠ” ë“¯í•œ 'ìì—°ìŠ¤ëŸ¬ìš´ 1ì¸ì¹­ ë¬¸ì¥'ìœ¼ë¡œ ìš”ì•½í•˜ì„¸ìš”. (~í•´ì„œ ì™”ì–´ìš”, ~ê°€ ì•„íŒŒìš”). ìš”ì•½ëœ ë¬¸ì¥ë§Œ í•œ ì¤„ë¡œ ì¶œë ¥í•˜ì„¸ìš”.";
    try {
      const response = await fetch(`https://generativelanguage.googleapis.com/v1beta/models/${GEMINI_MODEL}:generateContent?key=${GEMINI_API_KEY}`, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
          contents: [{ parts: [{ text: `ë‹¤ìŒ ë‚´ìš©ì„ í™˜ìì˜ ë§ì²˜ëŸ¼ ìš”ì•½í•´ì¤˜: ${rawText}` }] }],
          systemInstruction: { parts: [{ text: systemPrompt }] }
        })
      });
      const data = await response.json();
      const summary = data.candidates?.[0]?.content?.parts?.[0]?.text || rawText;
      setFormData(prev => ({ ...prev, symptomsSummary: summary }));
    } catch (err) { console.error(err); } finally { setIsProcessing(false); }
  };

  const sendToDiscord = async (finalData) => {
    const embed = {
      title: "ğŸ¦· ì„œìš¸ë³µìŒì¹˜ê³¼ ì‹ ê·œ ì ‘ìˆ˜ ì•Œë¦¼",
      color: 0x2563EB,
      fields: [
        { name: "ğŸ‘¤ ì„±í•¨", value: finalData.name, inline: true },
        { name: "ğŸ‚ ìƒë…„ì›”ì¼", value: finalData.birth, inline: true },
        { name: "ğŸ“ ì—°ë½ì²˜", value: finalData.phone, inline: true },
        { name: "ğŸ“ ì¦ìƒ ìš”ì•½ (AI)", value: finalData.symptomsSummary || finalData.symptomsRaw },
        { name: "ğŸ¤ ì›ë¬¸ ê¸°ë¡", value: finalData.symptomsRaw }
      ],
      timestamp: new Date().toISOString()
    };
    try {
      await fetch(DISCORD_WEBHOOK_URL, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({ embeds: [embed] })
      });
    } catch (err) { console.error(err); }
  };

  const speak = useCallback((text) => {
    if (!window.speechSynthesis) return;
    window.speechSynthesis.cancel();
    const utterance = new SpeechSynthesisUtterance(text);
    utterance.lang = 'ko-KR';
    utterance.rate = 0.95;
    utterance.onstart = () => setIsSpeaking(true);
    utterance.onend = () => {
      setIsSpeaking(false);
      if (['name', 'birth', 'phone', 'symptoms'].includes(currentStep.id)) startListening();
    };
    window.speechSynthesis.speak(utterance);
  }, [currentStep.id]);

  const startListening = () => {
    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
    if (!SpeechRecognition) {
      setError("í¬ë¡¬ ë¸Œë¼ìš°ì €ë¥¼ ì‚¬ìš©í•´ ì£¼ì„¸ìš”.");
      return;
    }
    if (isListening) return;
    const recognition = new SpeechRecognition();
    recognition.lang = 'ko-KR';
    recognition.interimResults = true;
    recognition.continuous = true;
    recognitionRef.current = recognition;
    recognition.onstart = () => setIsListening(true);
    recognition.onresult = (event) => {
      const isFinalResult = event.results[event.results.length - 1].isFinal;
      const latestTranscript = event.results[event.results.length - 1][0].transcript.trim();
      if (isFinalResult) {
        if (currentStep.id === 'symptoms') {
          setTranscript(prev => (prev ? `${prev} ${latestTranscript}` : latestTranscript));
        } else {
          let filtered = latestTranscript;
          if (currentStep.id === 'birth') filtered = latestTranscript.replace(/[^0-9ë…„ì›”ì¼\s]/g, "");
          if (currentStep.id === 'phone') filtered = latestTranscript.replace(/[^0-9]/g, "");
          setTranscript(filtered);
        }
      }
      if (currentStep.id === 'symptoms' && isFinalResult) {
        clearTimeout(summaryTimeoutRef.current);
        summaryTimeoutRef.current = setTimeout(() => {
          setTranscript(current => { summarizeSymptoms(current); return current; });
        }, 2000);
      }
    };
    recognition.onend = () => setIsListening(false);
    recognition.start();
  };

  const handleNextStep = async () => {
    if (recognitionRef.current) recognitionRef.current.stop();
    if (window.speechSynthesis) window.speechSynthesis.cancel();
    const stepId = currentStep.id;
    let nextData = { ...formData };
    if (stepId === 'name') nextData.name = transcript;
    else if (stepId === 'birth') nextData.birth = transcript;
    else if (stepId === 'phone') nextData.phone = transcript;
    else if (stepId === 'symptoms') {
      nextData.symptomsRaw = transcript;
      if (!nextData.symptomsSummary) await summarizeSymptoms(transcript);
    }
    setFormData(nextData);
    setTranscript('');
    if (isEditingMode) { setCurrentStepIndex(5); setIsEditingMode(false); }
    else { setCurrentStepIndex(prev => prev + 1); }
  };

  useEffect(() => {
    if (currentStepIndex > 0 || currentStep.id === 'welcome') speak(currentStep.question);
    if (currentStep.id === 'complete') sendToDiscord(formData);
  }, [currentStepIndex]);

  return (
    <div className="min-h-screen bg-slate-50 flex flex-col items-center p-8 font-sans">
      <div className="w-full max-w-xl mb-6">
        <h1 className="text-2xl font-black text-blue-900 mb-4">ğŸ¦· ì„œìš¸ë³µìŒì¹˜ê³¼</h1>
        <div className="w-full bg-white h-3 rounded-full overflow-hidden shadow-sm">
          <div className="bg-blue-600 h-full transition-all duration-1000" style={{ width: `${((currentStepIndex + 1) / STEPS.length) * 100}%` }} />
        </div>
      </div>
      <main className="w-full max-w-xl bg-white rounded-[3rem] shadow-xl border border-blue-50 flex flex-col min-h-[600px] overflow-hidden">
        <div className="p-10 bg-blue-600 text-white text-center">
          <h2 className="text-3xl font-black break-keep">{currentStep.question}</h2>
        </div>
        <div className="flex-1 p-8 flex flex-col justify-center">
          {currentStep.id === 'welcome' ? (
            <button onClick={() => setCurrentStepIndex(1)} className="w-full p-12 bg-blue-50 rounded-[3rem] text-2xl font-black text-blue-900">ì ‘ìˆ˜ ì‹œì‘í•˜ê¸°</button>
          ) : currentStep.id === 'complete' ? (
            <div className="text-center">
              <CheckCircle size={80} className="mx-auto text-green-500 mb-6" />
              <h3 className="text-3xl font-black mb-4">ì ‘ìˆ˜ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!</h3>
              <p className="text-xl text-slate-600">ê³§ ì—°ë½ë“œë¦¬ê² ìŠµë‹ˆë‹¤.</p>
            </div>
          ) : currentStep.id === 'confirm' ? (
            <div className="space-y-4">
              {['ì„±í•¨', 'ìƒë…„ì›”ì¼', 'ì—°ë½ì²˜', 'ì¦ìƒ'].map((label, i) => (
                <div key={i} className="p-4 bg-slate-50 rounded-2xl border border-slate-100">
                  <p className="text-xs font-black text-slate-400">{label}</p>
                  <p className="text-lg font-bold">{Object.values(formData)[i] || formData.symptomsSummary}</p>
                </div>
              ))}
              <button onClick={handleNextStep} className="w-full py-6 bg-blue-600 text-white rounded-[2rem] text-2xl font-black">ìµœì¢… ì ‘ìˆ˜ ì™„ë£Œ</button>
            </div>
          ) : (
            <div className="space-y-6">
              <textarea value={transcript} onChange={(e) => setTranscript(e.target.value)} className="w-full p-6 text-xl font-bold bg-slate-50 border-2 rounded-3xl min-h-[150px]" />
              <div className="flex gap-4">
                <button onClick={() => (isListening ? recognitionRef.current.stop() : startListening())} className={`flex-1 py-6 rounded-2xl font-black ${isListening ? 'bg-red-500 text-white' : 'bg-white border-2 border-blue-600 text-blue-600'}`}>
                  {isListening ? 'ë“£ëŠ” ì¤‘' : 'ìŒì„± ì…ë ¥'}
                </button>
                <button onClick={handleNextStep} className="flex-[2] py-6 bg-blue-600 text-white rounded-2xl font-black text-xl">ë‹¤ìŒ ë‹¨ê³„</button>
              </div>
            </div>
          )}
        </div>
      </main>
    </div>
  );
};
export default App;
